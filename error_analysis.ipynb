{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model/test_results.txt\n",
    "# co-models/ext_1000_isw_model/test_results.txt = 1521\n",
    "# co-models/ext_2290_isw_model/test_results.txt = 2290\n",
    "\n",
    "# co-models/\n",
    "# ext_1000_isw_model\t\text_4847_isw_model\n",
    "# ext_1000_top20_isw_model\text_504_isw_model\n",
    "# ext_2290_isw_model\t\text_isw_model\n",
    "# ext_3132_isw_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comapre the test result of baseline model and co-train model\n",
    "#### This will give us a insight about which NER tags are better or worse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_result(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        lines = (line.strip() for line in f)\n",
    "        eval_ls = []\n",
    "        for line in lines:\n",
    "            splits = line.split(\"    \")\n",
    "            splits = list(filter(None, splits))\n",
    "            eval_ls.append(splits)\n",
    "    eval_ls = eval_ls[2:-3]+[eval_ls[-1]]\n",
    "\n",
    "    float_list = []\n",
    "    for ls in eval_ls:\n",
    "        tmp_ls = []\n",
    "        for ele in ls:\n",
    "            try:\n",
    "                ele = float(ele)\n",
    "                tmp_ls.append(ele)\n",
    "            except:\n",
    "                tmp_ls.append(ele)\n",
    "        float_list.append(tmp_ls)\n",
    "    float_list = sorted(float_list, key = lambda x: x[0], reverse=False)\n",
    "    return float_list\n",
    "\n",
    "def get_better_worse_tags(baseline_ls, cotrain_ls):\n",
    "    better_ = []\n",
    "    worse_ = []\n",
    "    for (b_tag, b_p, b_r, b_f, b_s), (tag, p, r, f, s) in zip(baseline_ls, cotrain_ls):\n",
    "        assert b_tag == tag\n",
    "        # better f1 score results\n",
    "        if f>b_f:\n",
    "            better_.append([b_tag, b_f, f])\n",
    "        elif f<b_f:\n",
    "            worse_.append([b_tag, b_f, f])\n",
    "    return better_, worse_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF format for baseline model result\n",
    "# df = pd.DataFrame(baseline_ls[0:],columns=['Baseline model','precision', 'recall','f1-score','support'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with tag distribution \n",
    "### This will give us an insight about the distribution of the new labels added to the training set, and in comparison the distribution of labels in the training set before / after adding the new labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import joblib\n",
    "\n",
    "def get_stat(labels):\n",
    "    flat_list = [item for sublist in labels for item in sublist if item != 'O']\n",
    "    strList = list(map( lambda x: x.replace( 'B-', ''), flat_list))\n",
    "    strList = list(map( lambda x: x.replace( 'I-', ''), strList))\n",
    "\n",
    "    tag_list = list(Counter(strList).keys())\n",
    "    num_tags = list(Counter(strList).values())\n",
    "    dict_tags = dict(zip(tag_list, num_tags))\n",
    "\n",
    "    final_tag_dict = sorted(dict_tags.items(), key=lambda x: x[1], reverse=True)\n",
    "    return final_tag_dict\n",
    "\n",
    "def get_compare_df(ori_df, train_tags, ext_data_dir, ext_, better_, worse_):\n",
    "    com_tags, better_tags, worse_tags = [], [], []\n",
    "    for (tag, _) in train_tags:\n",
    "        better_ls = [tag for [tag, *_] in better_]\n",
    "        worse_ls = [tag for [tag, *_] in worse_]\n",
    "        if tag in list(ext_.keys()):\n",
    "            com_tags.append(ext_[tag])\n",
    "        else:\n",
    "            com_tags.append(0)\n",
    "        \n",
    "        if tag in better_ls:\n",
    "            better_tags.append(1)\n",
    "        else:\n",
    "            better_tags.append(0)\n",
    "            \n",
    "        if tag in worse_ls:\n",
    "            worse_tags.append(1)\n",
    "        else:\n",
    "            worse_tags.append(0)\n",
    "    \n",
    "    ori_df[ext_data_dir]=com_tags\n",
    "    ori_df['Better']=better_tags\n",
    "    ori_df['Worse']=worse_tags\n",
    "    return ori_df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>num</th>\n",
       "      <th>ext_data_1000_u_300</th>\n",
       "      <th>Better</th>\n",
       "      <th>Worse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPE</td>\n",
       "      <td>2803</td>\n",
       "      <td>954</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIME</td>\n",
       "      <td>2585</td>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRP</td>\n",
       "      <td>1886</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DUR</td>\n",
       "      <td>1634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAN</td>\n",
       "      <td>1253</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATE</td>\n",
       "      <td>1098</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PER</td>\n",
       "      <td>765</td>\n",
       "      <td>1056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FREQ</td>\n",
       "      <td>555</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AGE</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>412</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORG</td>\n",
       "      <td>382</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FAC</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>264</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SORD</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LOC</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EVT</td>\n",
       "      <td>156</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ART</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MISC</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TITLE</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MON</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QUANT</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RATE</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PERC</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LAW</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FRAC</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MED</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PROJ</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ADD</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CREAT</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag   num  ext_data_1000_u_300  Better  Worse\n",
       "0        GPE  2803                  954       1      0\n",
       "1       TIME  2585                  157       1      0\n",
       "2        NRP  1886                  276       1      0\n",
       "3        DUR  1634                    0       0      1\n",
       "4        LAN  1253                   53       0      1\n",
       "5       DATE  1098                   52       1      0\n",
       "6        PER   765                 1056       1      0\n",
       "7       FREQ   555                    6       1      0\n",
       "8        AGE   430                    0       1      0\n",
       "9   CARDINAL   412                  282       1      0\n",
       "10       ORG   382                    8       0      1\n",
       "11       FAC   279                    0       1      0\n",
       "12   ORDINAL   264                  152       0      1\n",
       "13      SORD   260                    0       1      0\n",
       "14       LOC   172                    0       0      1\n",
       "15       EVT   156                    2       1      0\n",
       "16       ART   127                    0       1      0\n",
       "17      MISC   107                    0       0      1\n",
       "18     TITLE    85                    0       0      1\n",
       "19       MON    72                    0       0      1\n",
       "20     QUANT    43                    0       1      0\n",
       "21      RATE    38                    0       1      0\n",
       "22      PERC    31                    0       0      0\n",
       "23       LAW    21                    0       0      0\n",
       "24      FRAC    19                    0       1      0\n",
       "25       MED    14                    0       0      0\n",
       "26      PROJ     9                    0       0      0\n",
       "27       ADD     8                    0       0      0\n",
       "28   PRODUCT     6                    0       0      0\n",
       "29     CREAT     3                    0       0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load better and wrose result \n",
    "\n",
    "# Load test result of baseline and cotrain model\n",
    "baseline_ls = load_eval_result(\"baseline_model/test_results.txt\")\n",
    "\n",
    "# _1521_ls = load_eval_result(\"co-models/ext_1000_isw_model/test_results.txt\")\n",
    "_2290_ls = load_eval_result(\"co-models/ext_2290_isw_model/test_results.txt\")\n",
    "\n",
    "# Shows the better and worse tags [[PER, 0.8, 0.9]]\n",
    "better_, worse_ = get_better_worse_tags(baseline_ls, _2290_ls)\n",
    "\n",
    "\n",
    "\n",
    "# Load origin train data and new adding ext data from co-training\n",
    "# Ori train data\n",
    "train_sents = joblib.load(\"data/train-isw-sentences.pkl\")\n",
    "train_labels = joblib.load(\"data/train-isw-labels.pkl\")\n",
    "\n",
    "# Extended train data, which generated from co-trainig method.\n",
    "# You should change the ext_data_dir to pick new adding train data.\n",
    "\n",
    "ext_data_dir = \"ext_data_1000_u_300\"\n",
    "\n",
    "# ext = joblib.load(\"ext_data/ext_data_1000/1521_ext_L_A_labels.pkl\")\n",
    "ext = joblib.load(\"ext_data/{}/2290_ext_L_A_labels.pkl\".format(ext_data_dir))\n",
    "\n",
    "\n",
    "# Get basic statistic of tags, present as dataframe for better visualizing.\n",
    "train_tags = get_stat(train_labels)\n",
    "ori_df = pd.DataFrame(train_tags[0:],columns=['Tag','num'])\n",
    "# ori_df\n",
    "\n",
    "\n",
    "# Get basic statistic of new adding tags.\n",
    "ext_tags = get_stat(ext)\n",
    "ext_df = pd.DataFrame(ext_tags[0:],columns=['Tag','num'])\n",
    "# Convert into dict format\n",
    "ext_ = dict(ext_tags)\n",
    "\n",
    "\n",
    "compare_df = get_compare_df(ori_df, train_tags, ext_data_dir, ext_, better_, worse_)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sentence and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from predict import Ner\n",
    "\n",
    "base_clf = Ner(model_dir=\"baseline_model/\")\n",
    "ext_clf = Ner(model_dir=\"co-models/ext_2290_isw_model/\")\n",
    "# Load test data, which used for error analysis\n",
    "test_sents = joblib.load(\"data/30-test-isw-sentences.pkl\")\n",
    "test_labels = joblib.load(\"data/30-test-isw-labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pred_by_tag(selected_tag, test_sents, test_labels, base_clf, ext_clf):\n",
    "    sele_ls = []\n",
    "    for sent, true_tag in zip(test_sents[:20], test_labels[:20]):\n",
    "        base_pred = base_clf.predict(sent)\n",
    "        ext_pred = ext_clf.predict(sent)\n",
    "        \n",
    "        base_tag = [dic['tag'] for dic in base_pred]\n",
    "        ext_tag = [dic['tag'] for dic in ext_pred]\n",
    "        \n",
    "        if any(x in base_tag for x in selected_tag) or any(x in ext_tag for x in selected_tag):\n",
    "            print(\"sent\", sent)\n",
    "            print(\"True\", true_tag)\n",
    "            print(\"base\", base_tag)\n",
    "            print(\"ext \", ext_tag)\n",
    "            print(\"\")\n",
    "            sele_ls.append((sent, true_tag, base_tag, ext_tag))\n",
    "        else:\n",
    "            pass\n",
    "    return sele_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better_tags: ['AGE', 'ART', 'CARDINAL', 'DATE', 'EVT', 'FAC', 'FRAC', 'FREQ', 'GPE', 'NRP', 'PER', 'QUANT', 'RATE', 'SORD', 'TIME', 'macro avg']\n",
      "\n",
      "Worse_tags: ['DUR', 'LAN', 'LOC', 'MISC', 'MON', 'ORDINAL', 'ORG', 'TITLE']\n"
     ]
    }
   ],
   "source": [
    "# Load test result of baseline and cotrain model\n",
    "baseline_ls = load_eval_result(\"baseline_model/test_results.txt\")\n",
    "\n",
    "# _1521_ls = load_eval_result(\"co-models/ext_1000_isw_model/test_results.txt\")\n",
    "_2290_ls = load_eval_result(\"co-models/ext_2290_isw_model/test_results.txt\")\n",
    "\n",
    "# Shows the better and worse tags [[PER, 0.8, 0.9]]\n",
    "better_, worse_ = get_better_worse_tags(baseline_ls, _2290_ls)\n",
    "\n",
    "## The \"selected_tag\" can be the ones \"better\" or \"worse\"\n",
    "better_tags = [tag for [tag, *_] in better_]\n",
    "print(\"Better_tags:\", better_tags)\n",
    "print(\"\")\n",
    "worse_tags = [tag for [tag, *_] in worse_]\n",
    "print(\"Worse_tags:\", worse_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sent Aber ich mein in größeren Massen kann man sagen dass der ökonomische Faktor erst im 20\n",
      "True ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE']\n",
      "base ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE']\n",
      "ext  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE']\n",
      "\n",
      "sent Und äh im 9\n",
      "True ['O', 'O', 'O', 'B-DATE']\n",
      "base ['O', 'O', 'O', 'B-GPE']\n",
      "ext  ['O', 'O', 'O', 'B-DATE']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "# tag can be either \"better\" or \"worse\" on ext model preds...\n",
    "selected_tag = [\"B-DATE\", \"I-DATE\"]\n",
    "sele_ls = select_pred_by_tag(selected_tag, test_sents, test_labels, base_clf, ext_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Save into txt\n",
    "analysis_ls = []\n",
    "for sent, true_tag in zip(test_sents, test_labels):\n",
    "    try:\n",
    "        base_pred = base_clf.predict(sent)\n",
    "        ext_pred = ext_clf.predict(sent)\n",
    "\n",
    "        base_tag = [dic['tag'] for dic in base_pred]\n",
    "        ext_tag = [dic['tag'] for dic in ext_pred]\n",
    "        analysis_ls.append((sent, true_tag, base_tag, ext_tag))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "with open(\"2290_analysis.txt\", \"w\", encoding=\"utf-8\") as writer:\n",
    "    for (sent, true_tag, base_tag, ext_tag) in analysis_ls:\n",
    "        writer.write(\"sent    \"+str(sent)+'\\n')\n",
    "        writer.write(\"True Tag\"+str(true_tag)+'\\n')\n",
    "        writer.write(\"baseline\"+str(base_tag)+'\\n')\n",
    "        writer.write(\"ext_tag \"+str(ext_tag)+'\\n')\n",
    "        writer.write('\\n')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('venv': conda)",
   "language": "python",
   "name": "python37664bitvenvcondaf245ac3bfe6249eb9f179268a6be08bb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
