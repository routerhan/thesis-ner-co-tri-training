{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model/test_results.txt\n",
    "# co-models/ext_1000_isw_model/test_results.txt = 1521\n",
    "# co-models/ext_2290_isw_model/test_results.txt = 2290\n",
    "\n",
    "# co-models/\n",
    "# ext_1000_isw_model\t\text_4847_isw_model\n",
    "# ext_1000_top20_isw_model\text_504_isw_model\n",
    "# ext_2290_isw_model\t\text_isw_model\n",
    "# ext_3132_isw_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comapre the test result of baseline model and co-train model\n",
    "#### This will give us a insight about which NER tags are better or worse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_result(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        lines = (line.strip() for line in f)\n",
    "        eval_ls = []\n",
    "        for line in lines:\n",
    "            splits = line.split(\"    \")\n",
    "            splits = list(filter(None, splits))\n",
    "            eval_ls.append(splits)\n",
    "    eval_ls = eval_ls[2:-3]+[eval_ls[-1]]\n",
    "\n",
    "    float_list = []\n",
    "    for ls in eval_ls:\n",
    "        tmp_ls = []\n",
    "        for ele in ls:\n",
    "            try:\n",
    "                ele = float(ele)\n",
    "                tmp_ls.append(ele)\n",
    "            except:\n",
    "                tmp_ls.append(ele)\n",
    "        float_list.append(tmp_ls)\n",
    "    float_list = sorted(float_list, key = lambda x: x[0], reverse=False)\n",
    "    return float_list\n",
    "\n",
    "def get_better_worse_tags(baseline_ls, cotrain_ls):\n",
    "    better_ = {}\n",
    "    worse_ = {}\n",
    "    for (b_tag, b_p, b_r, b_f, b_s), (tag, p, r, f, s) in zip(baseline_ls, cotrain_ls):\n",
    "        assert b_tag == tag\n",
    "        # better f1 score results\n",
    "        if f>b_f:\n",
    "            better_.update({b_tag:{'before': b_f, 'after': f}})\n",
    "        elif f<b_f:\n",
    "            worse_.update({b_tag:{'before': b_f, 'after': f}})\n",
    "    return better_, worse_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF format for baseline model result\n",
    "# df = pd.DataFrame(baseline_ls[0:],columns=['Baseline model','precision', 'recall','f1-score','support'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with tag distribution \n",
    "### This will give us an insight about the distribution of the new labels added to the training set, and in comparison the distribution of labels in the training set before / after adding the new labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import joblib\n",
    "\n",
    "def get_stat(labels):\n",
    "    flat_list = [item for sublist in labels for item in sublist if item != 'O']\n",
    "    strList = list(map( lambda x: x.replace( 'B-', ''), flat_list))\n",
    "    strList = list(map( lambda x: x.replace( 'I-', ''), strList))\n",
    "\n",
    "    tag_list = list(Counter(strList).keys())\n",
    "    num_tags = list(Counter(strList).values())\n",
    "    dict_tags = dict(zip(tag_list, num_tags))\n",
    "\n",
    "    final_tag_dict = sorted(dict_tags.items(), key=lambda x: x[1], reverse=True)\n",
    "    return final_tag_dict\n",
    "\n",
    "def get_compare_df(ori_df, train_tags, ext_data_dir, ext_, better_, worse_):\n",
    "    com_tags, better_tags, worse_tags = [], [], []\n",
    "    b_f, a_f = [], []\n",
    "    for (tag, _) in train_tags:\n",
    "        better_ls = list(better_.keys())\n",
    "        worse_ls = list(worse_.keys())\n",
    "        if tag in list(ext_.keys()):\n",
    "            com_tags.append(ext_[tag])\n",
    "        else:\n",
    "            com_tags.append(0)\n",
    "        \n",
    "        if tag in better_ls:\n",
    "            better_tags.append(1)\n",
    "            worse_tags.append(0)\n",
    "            b_f.append(better_[tag]['before'])\n",
    "            a_f.append(better_[tag]['after'])\n",
    "        elif tag in worse_ls:\n",
    "            better_tags.append(0)\n",
    "            worse_tags.append(1)\n",
    "            b_f.append(worse_[tag]['before'])\n",
    "            a_f.append(worse_[tag]['after'])\n",
    "        else:\n",
    "            better_tags.append(0)\n",
    "            worse_tags.append(0)\n",
    "            b_f.append(\"-\")\n",
    "            a_f.append(\"-\")\n",
    "    ori_df[ext_data_dir]=com_tags\n",
    "    ori_df['Better']=better_tags\n",
    "    ori_df['Worse']=worse_tags\n",
    "    ori_df['baseline_F1']=b_f\n",
    "    ori_df['ext_F1']=a_f\n",
    "    return ori_df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>num</th>\n",
       "      <th>ext_data_u_300_top_30</th>\n",
       "      <th>Better</th>\n",
       "      <th>Worse</th>\n",
       "      <th>baseline_F1</th>\n",
       "      <th>ext_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPE</td>\n",
       "      <td>2803</td>\n",
       "      <td>1543</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIME</td>\n",
       "      <td>2585</td>\n",
       "      <td>310</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8839</td>\n",
       "      <td>0.8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NRP</td>\n",
       "      <td>1886</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.9212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DUR</td>\n",
       "      <td>1634</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAN</td>\n",
       "      <td>1253</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>0.9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATE</td>\n",
       "      <td>1098</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>0.7921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PER</td>\n",
       "      <td>765</td>\n",
       "      <td>2987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>0.8546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FREQ</td>\n",
       "      <td>555</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.8078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AGE</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>412</td>\n",
       "      <td>810</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8283</td>\n",
       "      <td>0.8387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORG</td>\n",
       "      <td>382</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>0.6842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FAC</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.7882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>264</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.8033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SORD</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>0.7417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LOC</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7115</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EVT</td>\n",
       "      <td>156</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.8649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ART</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>0.3673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MISC</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TITLE</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.8525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MON</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>QUANT</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0.9474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RATE</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PERC</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LAW</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FRAC</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MED</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PROJ</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ADD</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CREAT</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag   num  ext_data_u_300_top_30  Better  Worse baseline_F1  ext_F1\n",
       "0        GPE  2803                   1543       1      0      0.9696  0.9737\n",
       "1       TIME  2585                    310       1      0      0.8839  0.8906\n",
       "2        NRP  1886                    392       1      0      0.9183  0.9212\n",
       "3        DUR  1634                     15       1      0      0.6667  0.6715\n",
       "4        LAN  1253                     70       0      1      0.9483  0.9468\n",
       "5       DATE  1098                    153       1      0      0.7697  0.7921\n",
       "6        PER   765                   2987       0      1      0.8622  0.8546\n",
       "7       FREQ   555                     18       1      0      0.7962  0.8078\n",
       "8        AGE   430                      0       0      1      0.6245  0.5789\n",
       "9   CARDINAL   412                    810       1      0      0.8283  0.8387\n",
       "10       ORG   382                     28       0      1      0.6866  0.6842\n",
       "11       FAC   279                      0       1      0      0.7602  0.7882\n",
       "12   ORDINAL   264                    337       0      1       0.823  0.8033\n",
       "13      SORD   260                      0       0      1      0.7516  0.7417\n",
       "14       LOC   172                      0       1      0      0.7115  0.7193\n",
       "15       EVT   156                      8       1      0      0.8364  0.8649\n",
       "16       ART   127                      0       1      0      0.3529  0.3673\n",
       "17      MISC   107                      0       0      1      0.6835  0.6353\n",
       "18     TITLE    85                      3       0      1      0.9032  0.8525\n",
       "19       MON    72                      0       1      0      0.8421  0.8889\n",
       "20     QUANT    43                      0       1      0      0.7368  0.9474\n",
       "21      RATE    38                      0       1      0           0  0.3333\n",
       "22      PERC    31                      0       0      0           -       -\n",
       "23       LAW    21                      0       0      0           -       -\n",
       "24      FRAC    19                      0       0      0           -       -\n",
       "25       MED    14                      0       0      0           -       -\n",
       "26      PROJ     9                      0       0      0           -       -\n",
       "27       ADD     8                      0       0      0           -       -\n",
       "28   PRODUCT     6                      0       0      0           -       -\n",
       "29     CREAT     3                      0       0      0           -       -"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load better and wrose result \n",
    "\n",
    "# Load test result of baseline and cotrain model\n",
    "baseline_ls = load_eval_result(\"baseline_model/test_results.txt\")\n",
    "\n",
    "# _1521_ls = load_eval_result(\"co-models/ext_1000_isw_model/test_results.txt\")\n",
    "_4847_ls = load_eval_result(\"co-models/ext_4847_isw_model/test_results.txt\")\n",
    "# _2290_ls = load_eval_result(\"co-models/ext_2290_isw_model/test_results.txt\")\n",
    "\n",
    "# Shows the better and worse tags [[PER, 0.8, 0.9]]\n",
    "better_, worse_ = get_better_worse_tags(baseline_ls, _4847_ls)\n",
    "\n",
    "\n",
    "\n",
    "# Load origin train data and new adding ext data from co-training\n",
    "# Ori train data\n",
    "train_sents = joblib.load(\"data/train-isw-sentences.pkl\")\n",
    "train_labels = joblib.load(\"data/train-isw-labels.pkl\")\n",
    "\n",
    "# Extended train data, which generated from co-trainig method.\n",
    "# You should change the ext_data_dir to pick new adding train data.\n",
    "\n",
    "# ext_data_dir = \"ext_data_1000_u_300\"\n",
    "ext_data_dir = \"ext_data_u_300_top_30\"\n",
    "\n",
    "# ext = joblib.load(\"ext_data/ext_data_1000/1521_ext_L_A_labels.pkl\")\n",
    "# ext = joblib.load(\"ext_data/{}/2290_ext_L_A_labels.pkl\".format(ext_data_dir))\n",
    "ext = joblib.load(\"ext_data/{}/4847_ext_L_A_labels.pkl\".format(ext_data_dir))\n",
    "\n",
    "\n",
    "# Get basic statistic of tags, present as dataframe for better visualizing.\n",
    "train_tags = get_stat(train_labels)\n",
    "ori_df = pd.DataFrame(train_tags[0:],columns=['Tag','num'])\n",
    "# ori_df\n",
    "\n",
    "\n",
    "# Get basic statistic of new adding tags.\n",
    "ext_tags = get_stat(ext)\n",
    "ext_df = pd.DataFrame(ext_tags[0:],columns=['Tag','num'])\n",
    "# Convert into dict format\n",
    "ext_ = dict(ext_tags)\n",
    "\n",
    "\n",
    "compare_df = get_compare_df(ori_df, train_tags, ext_data_dir, ext_, better_, worse_)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER': 2987,\n",
       " 'GPE': 1543,\n",
       " 'CARDINAL': 810,\n",
       " 'NRP': 392,\n",
       " 'ORDINAL': 337,\n",
       " 'TIME': 310,\n",
       " 'DATE': 153,\n",
       " 'LAN': 70,\n",
       " 'ORG': 28,\n",
       " 'FREQ': 18,\n",
       " 'DUR': 15,\n",
       " 'EVT': 8,\n",
       " 'TITLE': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ART': {'before': 0.3529, 'after': 0.3673},\n",
       " 'CARDINAL': {'before': 0.8283, 'after': 0.8387},\n",
       " 'DATE': {'before': 0.7697, 'after': 0.7921},\n",
       " 'DUR': {'before': 0.6667, 'after': 0.6715},\n",
       " 'EVT': {'before': 0.8364, 'after': 0.8649},\n",
       " 'FAC': {'before': 0.7602, 'after': 0.7882},\n",
       " 'FREQ': {'before': 0.7962, 'after': 0.8078},\n",
       " 'GPE': {'before': 0.9696, 'after': 0.9737},\n",
       " 'LOC': {'before': 0.7115, 'after': 0.7193},\n",
       " 'MON': {'before': 0.8421, 'after': 0.8889},\n",
       " 'NRP': {'before': 0.9183, 'after': 0.9212},\n",
       " 'QUANT': {'before': 0.7368, 'after': 0.9474},\n",
       " 'RATE': {'before': 0.0, 'after': 0.3333},\n",
       " 'TIME': {'before': 0.8839, 'after': 0.8906},\n",
       " 'macro avg': {'before': 0.8592, 'after': 0.8627}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGE': {'before': 0.6245, 'after': 0.5789},\n",
       " 'LAN': {'before': 0.9483, 'after': 0.9468},\n",
       " 'MISC': {'before': 0.6835, 'after': 0.6353},\n",
       " 'ORDINAL': {'before': 0.823, 'after': 0.8033},\n",
       " 'ORG': {'before': 0.6866, 'after': 0.6842},\n",
       " 'PER': {'before': 0.8622, 'after': 0.8546},\n",
       " 'SORD': {'before': 0.7516, 'after': 0.7417},\n",
       " 'TITLE': {'before': 0.9032, 'after': 0.8525}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worse_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check sentence and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from predict import Ner\n",
    "\n",
    "base_clf = Ner(model_dir=\"baseline_model/\")\n",
    "# ext_clf = Ner(model_dir=\"co-models/ext_2290_isw_model/\")\n",
    "ext_clf = Ner(model_dir=\"co-models/ext_4847_isw_model/\")\n",
    "\n",
    "# Load test data, which used for error analysis\n",
    "test_sents = joblib.load(\"data/30-test-isw-sentences.pkl\")\n",
    "test_labels = joblib.load(\"data/30-test-isw-labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pred_by_tag(selected_tag, test_sents, test_labels, base_clf, ext_clf):\n",
    "    sele_ls = []\n",
    "    for sent, true_tag in zip(test_sents[:20], test_labels[:20]):\n",
    "        base_pred = base_clf.predict(sent)\n",
    "        ext_pred = ext_clf.predict(sent)\n",
    "        \n",
    "        base_tag = [dic['tag'] for dic in base_pred]\n",
    "        ext_tag = [dic['tag'] for dic in ext_pred]\n",
    "        \n",
    "        if any(x in base_tag for x in selected_tag) or any(x in ext_tag for x in selected_tag):\n",
    "            print(\"sent\", sent)\n",
    "            print(\"True\", true_tag)\n",
    "            print(\"base\", base_tag)\n",
    "            print(\"ext \", ext_tag)\n",
    "            print(\"\")\n",
    "            sele_ls.append((sent, true_tag, base_tag, ext_tag))\n",
    "        else:\n",
    "            pass\n",
    "    return sele_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better_tags: ['ART', 'CARDINAL', 'DATE', 'DUR', 'EVT', 'FAC', 'FREQ', 'GPE', 'LOC', 'MON', 'NRP', 'QUANT', 'RATE', 'TIME', 'macro avg']\n",
      "\n",
      "Worse_tags: ['AGE', 'LAN', 'MISC', 'ORDINAL', 'ORG', 'PER', 'SORD', 'TITLE']\n"
     ]
    }
   ],
   "source": [
    "# Load test result of baseline and cotrain model\n",
    "baseline_ls = load_eval_result(\"baseline_model/test_results.txt\")\n",
    "\n",
    "# _1521_ls = load_eval_result(\"co-models/ext_1000_isw_model/test_results.txt\")\n",
    "# _2290_ls = load_eval_result(\"co-models/ext_2290_isw_model/test_results.txt\")\n",
    "_4847_ls = load_eval_result(\"co-models/ext_4847_isw_model/test_results.txt\")\n",
    "\n",
    "# Shows the better and worse tags [[PER, 0.8, 0.9]]\n",
    "better_, worse_ = get_better_worse_tags(baseline_ls, _4847_ls)\n",
    "\n",
    "## The \"selected_tag\" can be the ones \"better\" or \"worse\"\n",
    "better_tags = list(better_.keys())\n",
    "print(\"Better_tags:\", better_tags)\n",
    "print(\"\")\n",
    "worse_tags = list(worse_.keys())\n",
    "print(\"Worse_tags:\", worse_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better predicted NER tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sent Aber ich mein in größeren Massen kann man sagen dass der ökonomische Faktor erst im 20\n",
      "True ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE']\n",
      "base ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE']\n",
      "ext  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATE']\n",
      "\n",
      "sent Und äh im 9\n",
      "True ['O', 'O', 'O', 'B-DATE']\n",
      "base ['O', 'O', 'O', 'B-GPE']\n",
      "ext  ['O', 'O', 'O', 'B-DATE']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "# tag can be either \"better\" or \"worse\" on ext model preds...\n",
    "selected_tag = [\"B-DATE\", \"I-DATE\"]\n",
    "sele_ls = select_pred_by_tag(selected_tag, test_sents, test_labels, base_clf, ext_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worse predicted NER tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "# tag can be either \"better\" or \"worse\" on ext model preds...\n",
    "selected_tag = [\"B-ORDINAL\", \"I-ORDINAL\"]\n",
    "sele_ls = select_pred_by_tag(selected_tag, test_sents, test_labels, base_clf, ext_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Save into txt\n",
    "analysis_ls = []\n",
    "for sent, true_tag in zip(test_sents, test_labels):\n",
    "    try:\n",
    "        base_pred = base_clf.predict(sent)\n",
    "        ext_pred = ext_clf.predict(sent)\n",
    "\n",
    "        base_tag = [dic['tag'] for dic in base_pred]\n",
    "        ext_tag = [dic['tag'] for dic in ext_pred]\n",
    "        analysis_ls.append((sent, true_tag, base_tag, ext_tag))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "with open(\"4847_analysis.txt\", \"w\", encoding=\"utf-8\") as writer:\n",
    "    for (sent, true_tag, base_tag, ext_tag) in analysis_ls:\n",
    "        writer.write(\"sent    \"+str(sent)+'\\n')\n",
    "        writer.write(\"True Tag\"+str(true_tag)+'\\n')\n",
    "        writer.write(\"baseline\"+str(base_tag)+'\\n')\n",
    "        writer.write(\"ext_tag \"+str(ext_tag)+'\\n')\n",
    "        writer.write('\\n')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('venv': conda)",
   "language": "python",
   "name": "python37664bitvenvcondaf245ac3bfe6249eb9f179268a6be08bb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
